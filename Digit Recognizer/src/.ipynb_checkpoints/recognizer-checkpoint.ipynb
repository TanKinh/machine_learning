{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8    ...         pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0    ...     42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0    ...         0.219286      0.117095   \n",
       "std        0.0      0.0      0.0    ...         6.312890      4.633819   \n",
       "min        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "max        0.0      0.0      0.0    ...       254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6edb802f98>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['label'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort_index in module pandas.core.frame:\n",
      "\n",
      "sort_index(axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, by=None) method of pandas.core.frame.DataFrame instance\n",
      "    Sort object by labels (along an axis)\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    axis : index, columns to direct sorting\n",
      "    level : int or level name or list of ints or list of level names\n",
      "        if not None, sort on values in specified index level(s)\n",
      "    ascending : boolean, default True\n",
      "        Sort ascending vs. descending\n",
      "    inplace : bool, default False\n",
      "        if True, perform operation in-place\n",
      "    kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "         Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "         information.  `mergesort` is the only stable algorithm. For\n",
      "         DataFrames, this option is only applied when sorting on a single\n",
      "         column or label.\n",
      "    na_position : {'first', 'last'}, default 'last'\n",
      "         `first` puts NaNs at the beginning, `last` puts NaNs at the end.\n",
      "         Not implemented for MultiIndex.\n",
      "    sort_remaining : bool, default True\n",
      "        if true and sorting by level and index is multilevel, sort by other\n",
      "        levels too (in order) after sorting by specified level\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    sorted_obj : DataFrame\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_df.sort_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_df.iloc[:,1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_df.iloc[:,0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1= x_train[8][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6edb4bb2b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADsJJREFUeJzt3X+MVXeZx/HPAwxQqDRgt7NkoAJtaUVcqU6nuDa7bKoVq5U2mzQlbsNG4jTaas26u5KajcRdE/ZH69bE0B0XLDWK1bQVzBIrTkyx0cVOK0sLo0LrYGH50S6NlLb8mnn2jzk0I53zvbf3nnvPhef9SiZz73nOuefJZT6ce8/33vM1dxeAeMaU3QCAchB+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBjWvmzsbbBJ+oyc3cJRDKMb2iE37cqlm3rvCb2WJJ90oaK+k/3X1Vav2Jmqyr7dp6dgkgYav3Vr1uzS/7zWyspK9J+pCkeZKWmtm8Wh8PQHPV856/S9Jud3/O3U9I+o6kJcW0BaDR6gl/h6TnR9zfmy37A2bWbWZ9ZtZ3Usfr2B2AIjX8bL+797h7p7t3tmlCo3cHoEr1hH+fpJkj7s/IlgE4C9QT/ickXWZms81svKRbJG0spi0AjVbzUJ+7nzKzOyQ9quGhvrXuvqOwzgA0VF3j/O6+SdKmgnoB0ER8vBcIivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg6pql18wGJL0saVDSKXfvLKIpNFHXO5Pl3Z9O/4mMGz+YrM+68HBubdMVG5PbVrLi4HuS9Q2PLsytve2/XktuO+bxbTX1dDapK/yZv3D3Fwt4HABNxMt+IKh6w++SfmRmT5pZdxENAWiOel/2X+Pu+8zsIkmbzexX7r5l5ArZfwrdkjRRk+rcHYCi1HXkd/d92e9Dkh6R1DXKOj3u3ununW2aUM/uABSo5vCb2WQze8vp25Kuk/RMUY0BaKx6Xva3S3rEzE4/zrfd/YeFdAWg4czdm7azKTbNr7Zrm7a/KMa+dVpu7Vf3zEpuu3nRV5P1i8edV0tLrxsjy60NqXl/e2d6cTA9zv/+J25L1mf85Y4i2ynMVu/VET+c/6SPwFAfEBThB4Ii/EBQhB8IivADQRF+IKgivtWHBhs7b26y3r1hU27tw5M2V3j09FDeDb/+aLL+6snxyfoYyx/OG/KqRqQa4s7Zvcn6Y109yfpV3/hMsn7FJ9NDgUPHjiXrzcCRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpy/BYyZlL682Zx1e5L1GyYdya0NVdh3V9/HkvWLbtqVrJ83lL50d6taMzV92e8vdr89WX/X9c8m6ycumJJugHF+AGUh/EBQhB8IivADQRF+ICjCDwRF+IGguHR3C3j22wuS9f4/X5Ospy6PveAXf5Xc9uJP5U+hLUmn9h9I1tFauHQ3gIoIPxAU4QeCIvxAUIQfCIrwA0ERfiCoit/nN7O1kj4i6ZC7z8+WTZP0oKRZkgYk3ezuLzWuzXPbg+9NXyN+TIV/pvk/W5Zbm/2p9Dj9qRdeSNZx7qrmyH+/pMVnLFshqdfdL5PUm90HcBapGH533yLpzI+BLZG0Lru9TtKNBfcFoMFqfc/f7u77s9sHJLUX1A+AJqn7hJ8Pfzkg9wsCZtZtZn1m1ndSx+vdHYCC1Br+g2Y2XZKy34fyVnT3HnfvdPfONk2ocXcAilZr+DdKOn2KeZmkDcW0A6BZKobfzNZL+rmky81sr5ktl7RK0gfMbJek92f3AZxFKo7zu/vSnBJfzK/S7z+2MFm/vO2/k/Wh/FMqktJj+YMNHscf235Rsm5tbfnFCteSOLXvf2tpCVXiE35AUIQfCIrwA0ERfiAowg8ERfiBoJiiuwCVpthe+Dd9yfoESwyHVaGe4bxxc2Yl6/13/nGy/r2PfjVZXzA+/0/spaHXktte9ePPJOtXfHJHsj7UAtNgtzKO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFFN0F2DcjI5k/ftbN9b1+Iv7b0rWDz06I7f2d8u/m9x24Xl7kvXZ4yYm65Wkpg+v9FXlSt6+/vZk/ZK/TX9V+lzEFN0AKiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5y+ATUjPRNTxWPr7+vfNfKyu/TdyLH3FgauS9R/sml/zYz+y8D+S9blt45P1LcfS9Xuu/XBu7dTA75Lbnq0Y5wdQEeEHgiL8QFCEHwiK8ANBEX4gKMIPBFXxuv1mtlbSRyQdcvf52bKVkj4h6fQF4+9y902NarLV+fHjyfruL78rWX919eZk/XxLf45g4NSrubXrfvrp5LaXf/losj7YvytZn63tyXrKT3demqxfccHzyfqiiSeT9X+c155bm3COjvO/GdUc+e+XtHiU5V9x9wXZT9jgA2eriuF39y2SDjehFwBNVM97/jvMbLuZrTWzqYV1BKApag3/akmXSFogab+ku/NWNLNuM+szs76TSr83BtA8NYXf3Q+6+6C7D0n6uqSuxLo97t7p7p1tSp+4AtA8NYXfzKaPuHuTpGeKaQdAs1Qz1Lde0iJJF5rZXklflLTIzBZIckkDkm5rYI8AGqBi+N196SiL1zSgl3PWxB/8Ilm/5fnlybqPS79AG/NK/rmUS/t/mdx2MFltrMEKLzwrXYvglyeGkvVJA79P7Bt8wg8IivADQRF+ICjCDwRF+IGgCD8QVMWhPjTe0LaddW3f0sNWXe/MLS2evLrCxuclq//0uxuS9cGdv6nw+LFx5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnR0P9yX3513m5eFx6HL+S5zbNSdY7dKCuxz/XceQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY50dd9nzpvcn6pvav5dbSF96W3rHl48n6nH9/MllPX/gbHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiK4/xmNlPSA5LaNTx02uPu95rZNEkPSpolaUDSze7+UuNaRRleW9KVrO9Ynj+OL0ljLf/4MnDyaHLbS7/0arI+eDx/anJUVs2R/5Skz7n7PEkLJd1uZvMkrZDU6+6XSerN7gM4S1QMv7vvd/enstsvS+qX1CFpiaR12WrrJN3YqCYBFO9Nvec3s1mSrpS0VVK7u+/PSgc0/LYAwFmi6vCb2fmSHpL0WXc/MrLm7q6cj1KbWbeZ9ZlZ30nxHg1oFVWF38zaNBz8b7n7w9nig2Y2PatPl3RotG3dvcfdO929s00TiugZQAEqht/MTNIaSf3ufs+I0kZJy7LbyyRtKL49AI1SzVd63yfpVklPm9m2bNldklZJ+q6ZLZe0R9LNjWkR9Rg7ZUqyvnvFO5L19UvvTdaHNDZZPzr0Wm5tyeq/T27b0f+zZB31qRh+d39ckuWUry22HQDNwif8gKAIPxAU4QeCIvxAUIQfCIrwA0Fx6e4mOPHBzmT9aEdbsj5t7c+T9X2f/9Pc2sdv/WFy2w1Tf5Ksq8I4fiULNt6ZW5u7inH8MnHkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOdvglemp8fxH1r5r8n6gX9IXwHpPeOfyq0N1TlR9TeOzEzW7354SbI+9wvpzyigPBz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvmb4ILfHkvW058CkK4cX/v/0f/8f+nr8t+/eVGyPve+USdiet2sXYzjn6048gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUOae/r63mc2U9ICkdkkuqcfd7zWzlZI+IemFbNW73H1T6rGm2DS/2pjVG2iUrd6rI37Yqlm3mg/5nJL0OXd/yszeIulJM9uc1b7i7v9Wa6MAylMx/O6+X9L+7PbLZtYvqaPRjQForDf1nt/MZkm6UtLWbNEdZrbdzNaa2dScbbrNrM/M+k7qeF3NAihO1eE3s/MlPSTps+5+RNJqSZdIWqDhVwZ3j7adu/e4e6e7d7YpfS06AM1TVfjNrE3Dwf+Wuz8sSe5+0N0H3X1I0tcldTWuTQBFqxh+MzNJayT1u/s9I5ZPH7HaTZKeKb49AI1Szdn+90m6VdLTZrYtW3aXpKVmtkDDw38Dkm5rSIcAGqKas/2PSxpt3DA5pg+gtfEJPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFAVL91d6M7MXpC0Z8SiCyW92LQG3pxW7a1V+5LorVZF9vY2d/+jalZsavjfsHOzPnfvLK2BhFbtrVX7kuitVmX1xst+ICjCDwRVdvh7St5/Sqv21qp9SfRWq1J6K/U9P4DylH3kB1CSUsJvZovN7NdmttvMVpTRQx4zGzCzp81sm5n1ldzLWjM7ZGbPjFg2zcw2m9mu7Peo06SV1NtKM9uXPXfbzOz6knqbaWY/MbOdZrbDzO7Mlpf63CX6KuV5a/rLfjMbK+k3kj4gaa+kJyQtdfedTW0kh5kNSOp099LHhM3szyQdlfSAu8/Plv2LpMPuvir7j3Oqu3++RXpbKelo2TM3ZxPKTB85s7SkGyX9tUp87hJ93awSnrcyjvxdkna7+3PufkLSdyQtKaGPlufuWyQdPmPxEknrstvrNPzH03Q5vbUEd9/v7k9lt1+WdHpm6VKfu0RfpSgj/B2Snh9xf69aa8pvl/QjM3vSzLrLbmYU7dm06ZJ0QFJ7mc2MouLMzc10xszSLfPc1TLjddE44fdG17j7uyV9SNLt2cvbluTD79laabimqpmbm2WUmaVfV+ZzV+uM10UrI/z7JM0ccX9GtqwluPu+7PchSY+o9WYfPnh6ktTs96GS+3ldK83cPNrM0mqB566VZrwuI/xPSLrMzGab2XhJt0jaWEIfb2Bmk7MTMTKzyZKuU+vNPrxR0rLs9jJJG0rs5Q+0yszNeTNLq+TnruVmvHb3pv9Iul7DZ/yflfSFMnrI6WuOpP/JfnaU3Zuk9Rp+GXhSw+dGlkt6q6ReSbsk/VjStBbq7ZuSnpa0XcNBm15Sb9do+CX9dknbsp/ry37uEn2V8rzxCT8gKE74AUERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8I6v8BFnOKovsXH10AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(y_train[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tankinhbui/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/tankinhbui/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/tankinhbui/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C = 1e5)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(test_df.iloc[:, 0:].values)\n",
    "y_test = np.array(test_df.iloc[:, 0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(y_pre)+1)),\n",
    "                         \"Label\": y_pre})\n",
    "submissions.to_csv(\"mnist_tfkeras.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KMeans in module sklearn.cluster.k_means_:\n",
      "\n",
      "class KMeans(sklearn.base.BaseEstimator, sklearn.base.ClusterMixin, sklearn.base.TransformerMixin)\n",
      " |  K-Means clustering\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <k_means>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |  n_clusters : int, optional, default: 8\n",
      " |      The number of clusters to form as well as the number of\n",
      " |      centroids to generate.\n",
      " |  \n",
      " |  init : {'k-means++', 'random' or an ndarray}\n",
      " |      Method for initialization, defaults to 'k-means++':\n",
      " |  \n",
      " |      'k-means++' : selects initial cluster centers for k-mean\n",
      " |      clustering in a smart way to speed up convergence. See section\n",
      " |      Notes in k_init for more details.\n",
      " |  \n",
      " |      'random': choose k observations (rows) at random from data for\n",
      " |      the initial centroids.\n",
      " |  \n",
      " |      If an ndarray is passed, it should be of shape (n_clusters, n_features)\n",
      " |      and gives the initial centers.\n",
      " |  \n",
      " |  n_init : int, default: 10\n",
      " |      Number of time the k-means algorithm will be run with different\n",
      " |      centroid seeds. The final results will be the best output of\n",
      " |      n_init consecutive runs in terms of inertia.\n",
      " |  \n",
      " |  max_iter : int, default: 300\n",
      " |      Maximum number of iterations of the k-means algorithm for a\n",
      " |      single run.\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Relative tolerance with regards to inertia to declare convergence\n",
      " |  \n",
      " |  precompute_distances : {'auto', True, False}\n",
      " |      Precompute distances (faster but takes more memory).\n",
      " |  \n",
      " |      'auto' : do not precompute distances if n_samples * n_clusters > 12\n",
      " |      million. This corresponds to about 100MB overhead per job using\n",
      " |      double precision.\n",
      " |  \n",
      " |      True : always precompute distances\n",
      " |  \n",
      " |      False : never precompute distances\n",
      " |  \n",
      " |  verbose : int, default 0\n",
      " |      Verbosity mode.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None (default)\n",
      " |      Determines random number generation for centroid initialization. Use\n",
      " |      an int to make the randomness deterministic.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  copy_x : boolean, optional\n",
      " |      When pre-computing distances it is more numerically accurate to center\n",
      " |      the data first.  If copy_x is True (default), then the original data is\n",
      " |      not modified, ensuring X is C-contiguous.  If False, the original data\n",
      " |      is modified, and put back before the function returns, but small\n",
      " |      numerical differences may be introduced by subtracting and then adding\n",
      " |      the data mean, in this case it will also not ensure that data is\n",
      " |      C-contiguous which may cause a significant slowdown.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of jobs to use for the computation. This works by computing\n",
      " |      each of the n_init runs in parallel.\n",
      " |  \n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  algorithm : \"auto\", \"full\" or \"elkan\", default=\"auto\"\n",
      " |      K-means algorithm to use. The classical EM-style algorithm is \"full\".\n",
      " |      The \"elkan\" variation is more efficient by using the triangle\n",
      " |      inequality, but currently doesn't support sparse data. \"auto\" chooses\n",
      " |      \"elkan\" for dense data and \"full\" for sparse data.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cluster_centers_ : array, [n_clusters, n_features]\n",
      " |      Coordinates of cluster centers\n",
      " |  \n",
      " |  labels_ :\n",
      " |      Labels of each point\n",
      " |  \n",
      " |  inertia_ : float\n",
      " |      Sum of squared distances of samples to their closest cluster center.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Number of iterations run.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> from sklearn.cluster import KMeans\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
      " |  ...               [4, 2], [4, 4], [4, 0]])\n",
      " |  >>> kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
      " |  >>> kmeans.labels_\n",
      " |  array([0, 0, 0, 1, 1, 1], dtype=int32)\n",
      " |  >>> kmeans.predict([[0, 0], [4, 4]])\n",
      " |  array([0, 1], dtype=int32)\n",
      " |  >>> kmeans.cluster_centers_\n",
      " |  array([[1., 2.],\n",
      " |         [4., 2.]])\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  \n",
      " |  MiniBatchKMeans\n",
      " |      Alternative online implementation that does incremental updates\n",
      " |      of the centers positions using mini-batches.\n",
      " |      For large scale learning (say n_samples > 10k) MiniBatchKMeans is\n",
      " |      probably much faster than the default batch implementation.\n",
      " |  \n",
      " |  Notes\n",
      " |  ------\n",
      " |  The k-means problem is solved using either Lloyd's or Elkan's algorithm.\n",
      " |  \n",
      " |  The average complexity is given by O(k n T), were n is the number of\n",
      " |  samples and T is the number of iteration.\n",
      " |  \n",
      " |  The worst case complexity is given by O(n^(k+2/p)) with\n",
      " |  n = n_samples, p = n_features. (D. Arthur and S. Vassilvitskii,\n",
      " |  'How slow is the k-means method?' SoCG2006)\n",
      " |  \n",
      " |  In practice, the k-means algorithm is very fast (one of the fastest\n",
      " |  clustering algorithms available), but it falls in local minima. That's why\n",
      " |  it can be useful to restart it several times.\n",
      " |  \n",
      " |  If the algorithm stops before fully converging (because of ``tol`` of\n",
      " |  ``max_iter``), ``labels_`` and ``means_`` will not be consistent, i.e. the\n",
      " |  ``means_`` will not be the means of the points in each cluster.\n",
      " |  Also, the estimator will reassign ``labels_`` after the last iteration to\n",
      " |  make ``labels_`` consistent with ``predict`` on the training set.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KMeans\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClusterMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=None, algorithm='auto')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, sample_weight=None)\n",
      " |      Compute k-means clustering.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape=(n_samples, n_features)\n",
      " |          Training instances to cluster. It must be noted that the data\n",
      " |          will be converted to C ordering, which will cause a memory\n",
      " |          copy if the given data is not C-contiguous.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight (default: None)\n",
      " |  \n",
      " |  fit_predict(self, X, y=None, sample_weight=None)\n",
      " |      Compute cluster centers and predict cluster index for each sample.\n",
      " |      \n",
      " |      Convenience method; equivalent to calling fit(X) followed by\n",
      " |      predict(X).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight (default: None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : array, shape [n_samples,]\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, sample_weight=None)\n",
      " |      Compute clustering and transform X to cluster-distance space.\n",
      " |      \n",
      " |      Equivalent to fit(X).transform(X), but more efficiently implemented.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight (default: None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : array, shape [n_samples, k]\n",
      " |          X transformed in the new space.\n",
      " |  \n",
      " |  predict(self, X, sample_weight=None)\n",
      " |      Predict the closest cluster each sample in X belongs to.\n",
      " |      \n",
      " |      In the vector quantization literature, `cluster_centers_` is called\n",
      " |      the code book and each value returned by `predict` is the index of\n",
      " |      the closest code in the code book.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to predict.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight (default: None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : array, shape [n_samples,]\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |  \n",
      " |  score(self, X, y=None, sample_weight=None)\n",
      " |      Opposite of the value of X on the K-means objective.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight (default: None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Opposite of the value of X on the K-means objective.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform X to a cluster-distance space.\n",
      " |      \n",
      " |      In the new space, each dimension is the distance to the cluster\n",
      " |      centers.  Note that even if X is sparse, the array returned by\n",
      " |      `transform` will typically be dense.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : array, shape [n_samples, k]\n",
      " |          X transformed in the new space.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=10, random_state=0).fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 2, ..., 3, 6, 0], dtype=int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_df.iloc[:,1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm.classes:\n",
      "\n",
      "class SVC(sklearn.svm.base.BaseSVC)\n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time complexity\n",
      " |  is more than quadratic with the number of samples which makes it hard\n",
      " |  to scale to dataset with more than a couple of 10000 samples.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, optional (default=1.0)\n",
      " |      Penalty parameter C of the error term.\n",
      " |  \n",
      " |  kernel : string, optional (default='rbf')\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, optional (default=3)\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : float, optional (default='auto')\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      Current default is 'auto' which uses 1 / n_features,\n",
      " |      if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.std())\n",
      " |      as value of gamma. The current default of gamma, 'auto', will change\n",
      " |      to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n",
      " |      'auto' is used as a default indicating that no explicit value of gamma\n",
      " |      was passed.\n",
      " |  \n",
      " |  coef0 : float, optional (default=0.0)\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : boolean, optional (default=True)\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |  \n",
      " |  probability : boolean, optional (default=False)\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, and will slow down that method.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-3)\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, optional\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : {dict, 'balanced'}, optional\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default: False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, optional (default=-1)\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      The seed of the pseudo random number generator used when shuffling\n",
      " |      the data for probability estimates. If int, random_state is the\n",
      " |      seed used by the random number generator; If RandomState instance,\n",
      " |      random_state is the random number generator; If None, the random\n",
      " |      number generator is the RandomState instance used by `np.random`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : array-like, shape = [n_SV]\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : array-like, shape = [n_SV, n_features]\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the section about multi-class classification in the\n",
      " |      SVM section of the User Guide for details.\n",
      " |  \n",
      " |  coef_ : array, shape = [n_class * (n_class-1) / 2, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = SVC(gamma='auto')\n",
      " |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
      " |  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      " |      decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      " |      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      " |      tol=0.001, verbose=False)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVR\n",
      " |      Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC\n",
      " |      Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm.base.BaseSVC\n",
      " |      abc.NewBase\n",
      " |      sklearn.svm.base.BaseLibSVM\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Distance of the samples X to the separating hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes)\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : array, shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,)\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc = SVC(kernel='linear', C = 1e5)\n",
    "model_svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_soft_max = LogisticRegression(C = 1e5, solver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
